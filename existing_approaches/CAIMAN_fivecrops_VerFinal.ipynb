{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T20:19:35.703429Z",
     "iopub.status.busy": "2024-08-19T20:19:35.702920Z",
     "iopub.status.idle": "2024-08-19T20:19:40.381109Z",
     "shell.execute_reply": "2024-08-19T20:19:40.379931Z",
     "shell.execute_reply.started": "2024-08-19T20:19:35.703397Z"
    },
    "papermill": {
     "duration": 5.342248,
     "end_time": "2024-02-03T22:25:23.112817",
     "exception": false,
     "start_time": "2024-02-03T22:25:17.770569",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score, f1_score, precision_recall_curve, average_precision_score, classification_report \n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, balanced_accuracy_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import cv2\n",
    "from scipy.stats.mstats import gmean\n",
    "from custom_tranformations import RandomRotation\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from utils import encode_onehot, custom_label_binarize\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f'CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}')\n",
    "else:\n",
    "    print('CUDA is not available. Using CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T20:19:40.447868Z",
     "iopub.status.busy": "2024-08-19T20:19:40.447527Z",
     "iopub.status.idle": "2024-08-19T20:19:40.451853Z",
     "shell.execute_reply": "2024-08-19T20:19:40.450871Z",
     "shell.execute_reply.started": "2024-08-19T20:19:40.447841Z"
    },
    "papermill": {
     "duration": 0.130068,
     "end_time": "2024-02-03T22:25:23.357980",
     "exception": false,
     "start_time": "2024-02-03T22:25:23.227912",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#                             Global Configurations                             #\n",
    "################################################################################\n",
    "\n",
    "KFOLD_PATH = r\"E:\\Aamir Gulzar\\dataset\\splits\\kfolds_IDARS.csv\"\n",
    "DATA_PATH = r\"E:\\Aamir Gulzar\\dataset\\patches\"\n",
    "\n",
    "# GPU memory limit (commented out in your code)\n",
    "# torch.cuda.set_per_process_memory_fraction(0.9)\n",
    "\n",
    "# Some global metrics placeholders\n",
    "lmbda = 0.1\n",
    "best_auc_v = 0\n",
    "best_auc = 0\n",
    "n_slides = 0\n",
    "best_loss = 100000.\n",
    "best_f1_v = 0.\n",
    "best_Acc = 0.\n",
    "best_ap_v = 0.\n",
    "\n",
    "num_classes = 2\n",
    "label_names = ['nonMSI', 'MSI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T20:19:40.453764Z",
     "iopub.status.busy": "2024-08-19T20:19:40.453363Z",
     "iopub.status.idle": "2024-08-19T20:19:40.474196Z",
     "shell.execute_reply": "2024-08-19T20:19:40.473209Z",
     "shell.execute_reply.started": "2024-08-19T20:19:40.453730Z"
    },
    "papermill": {
     "duration": 0.028025,
     "end_time": "2024-02-03T22:25:23.396636",
     "exception": false,
     "start_time": "2024-02-03T22:25:23.368611",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--budget'], dest='budget', nargs=None, const=None, default=0.8, type=<class 'float'>, choices=None, required=False, help='the budget for how often the network can get hints', metavar='N')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='MSI And MSS Classification')\n",
    "parser.add_argument('--data_lib', type=str, default=KFOLD_PATH, help='path to train ')\n",
    "parser.add_argument('--val_lib', type=str, default=KFOLD_PATH, help='path to validation ')\n",
    "parser.add_argument('--test_lib', type=str, default=KFOLD_PATH, help='path to validation ')\n",
    "parser.add_argument('--problem', type=str, default='MSI_vs_MSS_T50R50', help='classification problem.')\n",
    "parser.add_argument('--pos_label', type=int, default=1, help='positive label.')\n",
    "parser.add_argument('--neg_label', type=int, default=0, help='negative label. If present.')\n",
    "parser.add_argument('--output', type=str, default='CAIMAN_Fivecrop_4Folds', help='new settings suggested by Sir')\n",
    "parser.add_argument('--folds', type=int, default=4, help='number of fold to execute')\n",
    "parser.add_argument('--batch_size', type=int, default=512, help='mini-batch size (default: 128)') # larger batch size is better try 512\n",
    "parser.add_argument('--nepochs', type=int, default=4, help='number of epochs')\n",
    "parser.add_argument('--workers', default=0, type=int, help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--test_every', default=1, type=int, help='test on val every (default: 10)')\n",
    "parser.add_argument('--weights', default=0.5, type=float, help='unbalanced positive class weight (default: 0.5, balanced classes)')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=0.001) # best 0.01\n",
    "parser.add_argument('--l2_reg', type=float, default=5e-3)\n",
    "parser.add_argument('--grad_bound', type=float, default=5.0)\n",
    "\n",
    "parser.add_argument('--r', default=50, type=int, help='how many rand tiles to consider (default: 10)') # try 50 percent of tiles\n",
    "parser.add_argument('--k', default=50, type=int, help='how many top k tiles to consider (default: 10)') # try 50 percent of tiles\n",
    "\n",
    "parser.add_argument('--budget', type=float, default=0.8, metavar='N',\n",
    "                    help='the budget for how often the network can get hints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#                     Aggregation Class (for tile-level merges)                #\n",
    "################################################################################\n",
    "\n",
    "class Aggregation:\n",
    "    \"\"\"\n",
    "    This class holds all tile-level aggregation methods. \n",
    "    It can be configured via 'aggregation_config' to enable or disable certain\n",
    "    aggregations or to conditionally save results to CSV, etc.\n",
    "    \"\"\"\n",
    "    def __init__(self, config=None):\n",
    "        \"\"\"\n",
    "        config: A dictionary to toggle aggregator methods \n",
    "                and saving behaviors. For example:\n",
    "                {\n",
    "                    'enable_binnedtopk': True,\n",
    "                    'enable_compute_aggregated_probabilities': True,\n",
    "                    'enable_compute_aggregated_predictions': True,\n",
    "                    'enable_group_avg_df': True,\n",
    "                    'save_csv': True\n",
    "                }\n",
    "        \"\"\"\n",
    "        if config is None:\n",
    "            config = {}\n",
    "        self.config = config\n",
    "\n",
    "    @staticmethod\n",
    "    def group_argtopk(groups, data, k=1):\n",
    "        \"\"\"\n",
    "        Return the indices of the top-k elements by group.\n",
    "        \"\"\"\n",
    "        order = np.lexsort((data, groups))\n",
    "        groups = groups[order]\n",
    "        data = data[order]\n",
    "        index = np.empty(len(groups), 'bool')\n",
    "        index[-k:] = True\n",
    "        index[:-k] = groups[k:] != groups[:-k]\n",
    "        return list(order[index])\n",
    "\n",
    "    @staticmethod\n",
    "    def group_max(groups, data, nmax):\n",
    "        \"\"\"\n",
    "        Return the maximum value in each group. \n",
    "        nmax is the maximum group ID + 1, used to fill results in an array.\n",
    "        \"\"\"\n",
    "        out = np.empty(nmax)\n",
    "        out[:] = np.nan\n",
    "        order = np.lexsort((data, groups))\n",
    "        groups = groups[order]\n",
    "        data = data[order]\n",
    "        index = np.empty(len(groups), 'bool')\n",
    "        index[-1] = True\n",
    "        index[:-1] = groups[1:] != groups[:-1]\n",
    "        out[groups[index]] = data[index]\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def group_avg(groups, data):\n",
    "        \"\"\"\n",
    "        Compute mean of data for each unique group.\n",
    "        \"\"\"\n",
    "        order = np.lexsort((data, groups))\n",
    "        groups = groups[order]\n",
    "        data = data[order]\n",
    "        unames, idx, counts = np.unique(groups, return_inverse=True, return_counts=True)\n",
    "        sum_pred = np.bincount(idx, weights=data)\n",
    "        mean_pred = sum_pred / counts\n",
    "        return mean_pred, sum_pred\n",
    "\n",
    "    @staticmethod\n",
    "    def get_binnedtopK_aggregation(group, data):\n",
    "        \"\"\"\n",
    "        Aggregate predictions by taking the top-1, mean, top percentages, \n",
    "        and a custom top-10 threshold-based score.\n",
    "        Returns topk_p and top10_sc:\n",
    "          - topk_p: The aggregated top predictions per WSI (binned)\n",
    "          - top10_sc: The special scoring mechanism for top 10 predictions \n",
    "                      above or below 0.5 threshold.\n",
    "        \"\"\"\n",
    "        wsi_dict = {}\n",
    "        for idx, g in enumerate(group):\n",
    "            g_id = wsi_dict.get(g, -1)\n",
    "            if g_id == -1:\n",
    "                wsi_dict[g] = [data[idx]]\n",
    "            else:\n",
    "                temp_data = wsi_dict[g]\n",
    "                temp_data.append(data[idx])\n",
    "                wsi_dict[g] = temp_data\n",
    "\n",
    "        topk_p = []  \n",
    "        top10_sc = []  \n",
    "        for each_wsi in wsi_dict.keys():\n",
    "            aggregated = []\n",
    "            wsi_predictions = wsi_dict[each_wsi]\n",
    "            wsi_predictions = np.array(wsi_predictions, dtype='float64')\n",
    "            wsi_predictions.sort()\n",
    "            aggregated.append(wsi_predictions[-1])           # top-1\n",
    "            aggregated.append(np.mean(wsi_predictions))      # average\n",
    "            for k_in in [1, 4]:\n",
    "                temp = wsi_predictions[-k_in:]\n",
    "                aggregated.append(np.mean(temp))\n",
    "            topk_p.append(np.mean(aggregated))\n",
    "\n",
    "            # For the top 10 predictions\n",
    "            top10_predictions = wsi_predictions[-10:]\n",
    "            if sum(top10_predictions[top10_predictions > 0.5]) > 0:\n",
    "                a = np.mean(top10_predictions[top10_predictions > 0.5])\n",
    "            else:\n",
    "                a = 0\n",
    "            if sum(top10_predictions[top10_predictions < 0.5]) > 0:\n",
    "                b = np.mean(top10_predictions[top10_predictions < 0.5])\n",
    "            else:\n",
    "                b = 0\n",
    "            top10_sc.append((a + a + b) / 3)\n",
    "        topk_p = np.array(topk_p, dtype='float64')\n",
    "        top10_sc = np.array(top10_sc, dtype='float64')\n",
    "        return topk_p, top10_sc\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_aggregated_probabilities(group, data, k=10):\n",
    "        \"\"\"\n",
    "        we need to use avg, max and top10\n",
    "        Compute multiple forms of aggregated probabilities (avg, max, sum, \n",
    "        median, gmean, and top-half-mean) for each group.\n",
    "        \"\"\"\n",
    "        wsi_dict = {}\n",
    "        for idx, g in enumerate(group):\n",
    "            g_id = wsi_dict.get(g, -1)\n",
    "            if g_id == -1:\n",
    "                wsi_dict[g] = [data[idx]]\n",
    "            else:\n",
    "                temp_data = wsi_dict[g]\n",
    "                temp_data.append(data[idx])\n",
    "                wsi_dict[g] = temp_data\n",
    "\n",
    "        avg_p = []\n",
    "        max_p = []\n",
    "        sum_p = []\n",
    "        md_p = []\n",
    "        gm_p = []\n",
    "        top_p = []\n",
    "\n",
    "        for each_wsi in wsi_dict.keys():\n",
    "            wsi_predictions = np.array(wsi_dict[each_wsi], dtype='float64')\n",
    "            avg_p.append(np.mean(wsi_predictions))\n",
    "            max_p.append(np.max(wsi_predictions))\n",
    "            # sum_p.append(np.sum(wsi_predictions))\n",
    "            # md = np.median(wsi_predictions)\n",
    "            # md_p.append(md)\n",
    "            # gm_p.append(gmean(wsi_predictions))\n",
    "            # top_p.append(np.mean(wsi_predictions[wsi_predictions >= md]))\n",
    "        avg_p = np.array(avg_p, dtype='float64')\n",
    "        max_p = np.array(max_p, dtype='float64')\n",
    "        # sum_p = np.array(sum_p, dtype='float64')\n",
    "        # md_p = np.array(md_p, dtype='float64')\n",
    "        # gm_p = np.array(gm_p, dtype='float64')\n",
    "        # top_p = np.array(top_p, dtype='float64')\n",
    "        return avg_p, max_p\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_aggregated_predictions(group, data):\n",
    "        \"\"\"\n",
    "        Compute majority-vote predictions for each WSI. \n",
    "        Returns:\n",
    "          mv_pred: majority class for each WSI\n",
    "          n_pred:  array of raw counts for each class\n",
    "        \"\"\"\n",
    "        wsi_dict = {}\n",
    "        for idx, g in enumerate(group):\n",
    "            if g not in wsi_dict:\n",
    "                wsi_dict[g] = [data[idx]]\n",
    "            else:\n",
    "                wsi_dict[g].append(data[idx])\n",
    "\n",
    "        mv_pred = []\n",
    "        n_pred = []\n",
    "        for each_wsi in wsi_dict.keys():\n",
    "            wsi_predictions = wsi_dict[each_wsi]\n",
    "            wsi_pred_class = []\n",
    "            for cl in range(num_classes):\n",
    "                wsi_pred_class.append(wsi_predictions.count(cl))\n",
    "\n",
    "            mj_vt = np.argmax(wsi_pred_class)\n",
    "            mv_pred.append(mj_vt)\n",
    "            n_pred.append(wsi_pred_class)\n",
    "\n",
    "        n_pred = np.array(n_pred, dtype='float64')\n",
    "        mv_pred = np.array(mv_pred, dtype='float64')\n",
    "        return mv_pred, n_pred\n",
    "\n",
    "    @staticmethod\n",
    "    def group_avg_df(groups, data):\n",
    "        \"\"\"\n",
    "        Group top-10 aggregator using pandas. \n",
    "        Returns the mean of nlargest(10) for each group.\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame({'Slide': groups, 'value': data})\n",
    "        group_average_df = df.groupby('Slide')['value'].apply(lambda grp: grp.nlargest(10).mean())\n",
    "        group_average = group_average_df.tolist()\n",
    "        return group_average\n",
    "\n",
    "    @staticmethod\n",
    "    def get_topMedtraining(group, data):\n",
    "        \"\"\"\n",
    "        Returns indices of tiles whose probabilities are >= the median \n",
    "        probability within each WSI group.\n",
    "        \"\"\"\n",
    "        wsi_dict = {}\n",
    "        for idx, g in enumerate(group):\n",
    "            if g not in wsi_dict:\n",
    "                wsi_dict[g] = [data[idx]]\n",
    "            else:\n",
    "                wsi_dict[g].append(data[idx])\n",
    "\n",
    "        top_p = []\n",
    "        for each_wsi in wsi_dict.keys():\n",
    "            wsi_predictions = np.array(wsi_dict[each_wsi], dtype='float64')\n",
    "            md = np.median(wsi_predictions)\n",
    "            start_i = np.squeeze(np.argwhere(group == each_wsi))[0]\n",
    "            indices = np.squeeze(np.argwhere(wsi_predictions >= md)) + start_i\n",
    "            top_p.extend(indices)\n",
    "\n",
    "        top_p = np.array(top_p, dtype='int64')\n",
    "        return top_p\n",
    "\n",
    "    @staticmethod\n",
    "    def get_topKtraining(group, data, k=5):\n",
    "        \"\"\"\n",
    "        Returns the indices of the top-k% (or top-k absolute if you want) \n",
    "        probabilities for each WSI group.\n",
    "        \"\"\"\n",
    "        wsi_dict = {}\n",
    "        for idx, g in enumerate(group):\n",
    "            if g not in wsi_dict:\n",
    "                wsi_dict[g] = [data[idx]]\n",
    "            else:\n",
    "                wsi_dict[g].append(data[idx])\n",
    "\n",
    "        topk_p = []\n",
    "        for each_wsi in wsi_dict.keys():\n",
    "            wsi_predictions = np.array(wsi_dict[each_wsi], dtype='float64')\n",
    "            start_i = np.squeeze(np.argwhere(group == each_wsi)[0])\n",
    "            perc = int((k / 100) * len(wsi_predictions)) + 1\n",
    "            topk = wsi_predictions.argsort()[-perc:]\n",
    "            topk_p.extend(topk + start_i)\n",
    "\n",
    "        topk_p = np.squeeze(np.array(topk_p, dtype='int64'))\n",
    "        return topk_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#                     Evaluation Class (metrics, plotting, etc.)               #\n",
    "################################################################################\n",
    "\n",
    "class Evaluation:\n",
    "    \"\"\"\n",
    "    This class holds evaluation-related methods such as metrics calculation, \n",
    "    confusion matrices, classification reports, etc. \n",
    "    \"\"\"\n",
    "    def __init__(self, config=None):\n",
    "        \"\"\"\n",
    "        config: A dictionary to toggle certain evaluation steps or CSV saving.\n",
    "                For example:\n",
    "                {\n",
    "                    'enable_plot_metrics': True,\n",
    "                    'enable_confusion_matrix': True,\n",
    "                    'save_csv': True\n",
    "                }\n",
    "        \"\"\"\n",
    "        if config is None:\n",
    "            config = {}\n",
    "        self.config = config\n",
    "    ############################################################################\n",
    "    #                          Original Evaluation Methods                     #\n",
    "    ############################################################################\n",
    "\n",
    "    @staticmethod\n",
    "    def cutoff_youdens_j(fpr, tpr, thresholds):\n",
    "        \"\"\"\n",
    "        Return the cutoff threshold that maximizes Youden's J statistic (tpr - fpr).\n",
    "        \"\"\"\n",
    "        j_scores = tpr - fpr\n",
    "        j_ordered = sorted(zip(j_scores, thresholds))\n",
    "        return j_ordered[-1][1]\n",
    "\n",
    "    @staticmethod\n",
    "    def cal_f1_score(targets, prediction, cutoff):\n",
    "        \"\"\"\n",
    "        Calculate F1 score (weighted) for binary predictions \n",
    "        given a cutoff threshold.\n",
    "        \"\"\"\n",
    "        prediction = np.array(prediction)\n",
    "        targets = np.array(targets)\n",
    "        f1score = f1_score(targets, prediction, average='weighted')\n",
    "        return f1score\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_metrics(target, prediction):\n",
    "        \"\"\"\n",
    "        Calculate multiple metrics: \n",
    "        - AUC (from ROC), \n",
    "        - F1 (with Youden J threshold), \n",
    "        - Average Precision (PR AUC).\n",
    "        \"\"\"\n",
    "        fpr, tpr, thresholds = roc_curve(target, prediction)\n",
    "        cutoff = Evaluation.cutoff_youdens_j(fpr, tpr, thresholds)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        f1score = Evaluation.cal_f1_score(target, prediction, cutoff)\n",
    "        precision, recall, _ = precision_recall_curve(target, prediction, zero_division=1)\n",
    "        average_precision = average_precision_score(target, prediction, zero_division=1)\n",
    "        return f1score, average_precision, roc_auc, cutoff\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_accuracy(output, target):\n",
    "        \"\"\"\n",
    "        Compute classification accuracy given output logits and ground truth target.\n",
    "        \"\"\"\n",
    "        preds = output.max(1, keepdim=True)[1]\n",
    "        correct = preds.eq(target.view_as(preds)).sum()\n",
    "        acc = correct.float() / preds.shape[0]\n",
    "        return acc\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_auc(labels, predictions):\n",
    "        # binary_labels = custom_label_binarize(np.array(labels), classes=[i for i in range(num_classes)])\n",
    "        # auc_list = []\n",
    "        # for cl in range(num_classes):\n",
    "        #     fpr, tpr, thresholds = roc_curve(binary_labels[:, cl], predictions[:, cl])\n",
    "        #     auc_list.append(auc(fpr, tpr))\n",
    "        aucscore = roc_auc_score(labels, predictions[:, 1])\n",
    "        return aucscore\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_metrics(target, prediction, set):\n",
    "        \"\"\"\n",
    "        Plot and save ROC and Precision-Recall curves.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt  # local import to match old structure\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(target, prediction)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print('roc_auc is:', roc_auc)\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(target, prediction, zero_division=1)\n",
    "        average_precision = average_precision_score(target, prediction, zero_division=1)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        lw = 2\n",
    "\n",
    "        # Subplot 1: ROC\n",
    "        plt.subplot(121)\n",
    "        plt.plot(fpr, tpr, color='darkorange',\n",
    "                 lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve, AUC={0:0.2f}'.format(roc_auc))\n",
    "        plt.legend(loc=\"lower right\")\n",
    "\n",
    "        # Subplot 2: Precision-Recall\n",
    "        plt.subplot(122)\n",
    "        plt.step(recall, precision, alpha=0.4, color='darkorange', where='post')\n",
    "        plt.fill_between(recall, precision, alpha=0.2, color='navy', step='post')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.ylim([0, 1.05])\n",
    "        plt.xlim([0, 1])\n",
    "        plt.title('Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "\n",
    "        plt.savefig(os.path.join(args.output, 'roc_pr' + set + '.png'))\n",
    "        plt.close(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                            Model Definition                                 #\n",
    "###############################################################################\n",
    "import copy\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard ResNet34-based feature extractor + classifier + confidence head,\n",
    "    with no internal logic for multi-crop.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.model_resnet = models.resnet34(weights='DEFAULT')\n",
    "        num_ftrs = self.model_resnet.fc.in_features\n",
    "        self.model_resnet.fc = nn.Identity()  # remove the original final FC\n",
    "        self.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        self.conf = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x => shape [N, 3, H, W]\n",
    "        N can be any batch size (including B*5 if flattened outside).\n",
    "        \"\"\"\n",
    "        features = self.model_resnet(x)        # => [N, num_ftrs]\n",
    "        logit = self.classifier(features)      # => [N, num_classes]\n",
    "        conf = self.conf(features)             # => [N, 1]\n",
    "        return logit, conf\n",
    "\n",
    "def targets_for_wsi_loss(tile_labels, wsi_ids, wsi, cl):\n",
    "    tile_labels[tile_labels == cl] = -1\n",
    "    tile_labels[wsi_ids == wsi] = cl\n",
    "    return tile_labels\n",
    "\n",
    "def encode_onehot_new(labels, n_classes):\n",
    "    device = labels.device\n",
    "    eye = torch.eye(n_classes, device=device)\n",
    "    return eye[labels]\n",
    "\n",
    "# from old CAIMAN implementation\n",
    "def encode_onehot(labels, n_classes):\n",
    "    onehot = torch.FloatTensor(labels.size()[0], n_classes)\n",
    "    labels = labels.data\n",
    "    if labels.is_cuda:\n",
    "        onehot = onehot.cuda()\n",
    "    onehot.zero_()\n",
    "    onehot.scatter_(1, labels.view(-1, 1), 1)\n",
    "    return onehot\n",
    "\n",
    "def train(run, loader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    xentropy_loss_avg = 0.\n",
    "    confidence_loss_avg = 0.\n",
    "    slide_loss_avg = 0.\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "\n",
    "    for i, (inputs, templabels, wsi_ids) in enumerate(loader):\n",
    "        # inputs => shape [batch_size, 5, 3, 224, 224]\n",
    "        # templabels => shape [batch_size]\n",
    "        # 1) Flatten the 5-crop dimension into the batch dimension\n",
    "        tile_labels = copy.deepcopy(templabels)\n",
    "        b, ncrops, c, h, w = inputs.shape      # e.g. (B, 5, 3, 224, 224)\n",
    "        inputs = inputs.view(b * ncrops, c, h, w).cuda()  # => (B*5, 3, 224, 224)\n",
    "\n",
    "        # Move labels to GPU\n",
    "        templabels = templabels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 2) Forward pass (model sees a batch of size B*5)\n",
    "        output, conf = model(inputs)           # => (B*5, num_classes), (B*5, 1)\n",
    "\n",
    "        # 3) Reshape back into (B, 5, ...)\n",
    "        output = output.view(b, ncrops, -1)    # => (B, 5, num_classes)\n",
    "        conf = conf.view(b, ncrops, -1)        # => (B, 5, 1)\n",
    "\n",
    "        # 4) Average over the 5 crops\n",
    "        output = output.mean(dim=1)           # => (B, num_classes)\n",
    "        conf = conf.mean(dim=1)               # => (B, 1)\n",
    "\n",
    "        # 5) Proceed with the existing logic\n",
    "        pred_original = F.softmax(output, dim=-1)\n",
    "        confidence = torch.sigmoid(conf)\n",
    "\n",
    "        eps = 1e-12\n",
    "        pred_original = torch.clamp(pred_original, eps, 1. - eps)\n",
    "        confidence = torch.clamp(confidence, eps, 1. - eps)\n",
    "\n",
    "        # Convert to one-hot for your custom weighting logic\n",
    "        labels_onehot = encode_onehot(templabels, num_classes)  # => (B, num_classes)\n",
    "\n",
    "        # Weighted combination of predicted distribution and the one-hot label\n",
    "        pred_new = pred_original * confidence + labels_onehot * (1 - confidence)\n",
    "        pred_new = torch.log(pred_new)\n",
    "\n",
    "        xentropy_loss = criterion(pred_new, templabels)\n",
    "        confidence_loss = torch.mean(-torch.log(confidence))\n",
    "\n",
    "        # Slide-level consistency loss (if needed, placeholder)\n",
    "        slide_loss = 0.\n",
    "        for cl in range(1, num_classes):\n",
    "            wsi_ids_temp = wsi_ids[tile_labels==cl]            \n",
    "            wsi_ids_unique = wsi_ids_temp.unique()\n",
    "            if len(wsi_ids_unique) >= 1:\n",
    "                for wsi in wsi_ids_unique:\n",
    "                    target_group_tiles = targets_for_wsi_loss(tile_labels, wsi_ids, wsi, cl)\n",
    "                    target_group_tiles = target_group_tiles.cuda()\n",
    "                    sloss = criterion(pred_new, target_group_tiles)\n",
    "                    slide_loss += sloss\n",
    "                slide_loss = slide_loss / len(wsi_ids_unique)\n",
    "                slide_loss_avg = slide_loss.item() * b\n",
    "\n",
    "        total_loss = xentropy_loss + confidence_loss + slide_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 6) Track stats\n",
    "        running_loss += total_loss.item() * b\n",
    "        acc = Evaluation.calculate_accuracy(output, templabels)\n",
    "        running_acc += acc.item() * b\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item() * b\n",
    "        confidence_loss_avg += confidence_loss.item() * b\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\n",
    "                \"Train Epoch: [{:3d}/{:3d}] Batch: {:3d}/{:3d}, Loss: {:.4f}, acc: {:.2f}%, xent: {:.4f}, conf: {:.4f}, slide: {:.4f}\".format(\n",
    "                    run + 1, \n",
    "                    args.nepochs, \n",
    "                    i + 1, \n",
    "                    len(loader),\n",
    "                    running_loss / ((i + 1) * b),\n",
    "                    (100 * running_acc) / ((i + 1) * b),\n",
    "                    xentropy_loss_avg / ((i + 1) * b),\n",
    "                    confidence_loss_avg / ((i + 1) * b),\n",
    "                    slide_loss_avg / ((i + 1) * b)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # If you need to return predictions for some reason, adapt accordingly\n",
    "    return running_loss / len(loader.dataset), running_acc / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(run, loader, model, criterion):\n",
    "    model.eval()\n",
    "    running_acc = 0.\n",
    "    running_loss = 0.\n",
    "\n",
    "    # We'll store per-sample probabilities, predictions, and confidence.\n",
    "    # 'len(loader.dataset)' should be the total number of *images* (where each image has 5 crops).\n",
    "    probs = torch.FloatTensor(len(loader.dataset), num_classes)\n",
    "    preds = torch.FloatTensor(len(loader.dataset))\n",
    "    confidence = torch.FloatTensor(len(loader.dataset))\n",
    "\n",
    "    index_offset = 0  # --- 5-crop change ---\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, target, wsi_id) in enumerate(loader):\n",
    "            \"\"\"\n",
    "            inputs => shape [batch_size, 5, 3, 224, 224]\n",
    "            target => shape [batch_size]\n",
    "            We want to flatten the 5 crops per sample into a single batch dimension,\n",
    "            pass them to the model, then reshape back and average.\n",
    "            \"\"\"\n",
    "            b, ncrops, c, h, w = inputs.shape  # e.g. (B, 5, 3, 224, 224)\n",
    "            inputs = inputs.view(-1, c, h, w).cuda()  # (B*5, 3, 224, 224)\n",
    "            target = target.cuda()\n",
    "\n",
    "            # Forward pass: the model now treats this as a batch of B*5 single images\n",
    "            output, conf = model(inputs)      # => (B*5, num_classes), (B*5, 1)\n",
    "\n",
    "            # Reshape back to (B, 5, ...) and average\n",
    "            output = output.view(b, ncrops, -1).mean(dim=1)  # => (B, num_classes)\n",
    "            conf = conf.view(b, ncrops, -1).mean(dim=1)      # => (B, 1)\n",
    "\n",
    "            # Compute loss and accuracy\n",
    "            loss = criterion(output, target)\n",
    "            acc = Evaluation.calculate_accuracy(output, target)\n",
    "\n",
    "            # Softmax over classes\n",
    "            y = F.softmax(output, dim=-1)         # => (B, num_classes)\n",
    "            # Sigmoid confidence (already (B,1)), reshape to 1D\n",
    "            conf = torch.sigmoid(conf).view(-1)   # => (B,)\n",
    "\n",
    "            # Predictions\n",
    "            pred_value, pred = torch.max(output.data, 1)\n",
    "            #store the probabilities, predictions and confidence\n",
    "            batch_size_now = b\n",
    "            probs[index_offset:index_offset + batch_size_now] = y.detach().clone()\n",
    "            preds[index_offset:index_offset + batch_size_now] = pred.detach().clone()\n",
    "            confidence[index_offset:index_offset + batch_size_now] = conf.detach().clone()\n",
    "            index_offset += batch_size_now\n",
    "\n",
    "            running_loss += loss.item() * batch_size_now\n",
    "            running_acc += acc.item() * batch_size_now\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print('Inference\\tEpoch: [{:3d}/{:3d}]\\tBatch: [{:3d}/{}]\\t'\n",
    "                      'Validation: Loss: {:.4f}, acc: {:0.2f}%'.format(\n",
    "                    run + 1, \n",
    "                    args.nepochs, \n",
    "                    i + 1, \n",
    "                    len(loader),\n",
    "                    running_loss / ((i + 1) * batch_size_now),\n",
    "                    (100. * running_acc) / ((i + 1) * batch_size_now) \n",
    "                ))\n",
    "\n",
    "        # Print some confidence stats\n",
    "        confidence_np = confidence.cpu().numpy()\n",
    "        print('Confidence\\tMin: {:0.4f}\\tAverage: {:.4f}\\tMax: {:0.4f}'.format(\n",
    "            np.min(confidence_np), np.mean(confidence_np), np.max(confidence_np)\n",
    "        ))\n",
    "\n",
    "    return (\n",
    "        probs.cpu().numpy(),\n",
    "        running_loss / len(loader.dataset),\n",
    "        running_acc / len(loader.dataset),\n",
    "        preds.cpu().numpy(),\n",
    "        confidence_np\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#                                Dataset Class                                 #\n",
    "################################################################################\n",
    "def get_split_indices(lib, test_fold, val_fold):\n",
    "    \"\"\"\n",
    "    lib: DataFrame with a column named 'fold' \n",
    "         that has values in [0, 1, 2, 3].\n",
    "    test_fold, val_fold: integers from 0..3\n",
    "    returns: three lists => train_idx, val_idx, test_idx\n",
    "    \"\"\"\n",
    "    # Extract all folds\n",
    "    all_folds = lib['fold'].values.tolist()\n",
    "\n",
    "    test_idx = [i for i, f in enumerate(all_folds) if f == test_fold]\n",
    "    val_idx  = [i for i, f in enumerate(all_folds) if f == val_fold]\n",
    "    train_idx = [i for i, f in enumerate(all_folds)\n",
    "                 if f not in (test_fold, val_fold)]\n",
    "    \n",
    "    return train_idx, val_idx, test_idx\n",
    "\n",
    "\n",
    "class MILdataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    A custom Dataset to handle multiple WSI tiles from a library CSV.\n",
    "    Each tile is read at 512×512, then we apply a transform that does\n",
    "    FiveCrop(224). This results in a 5-crop for each tile.\n",
    "    \"\"\"\n",
    "    def __init__(self, libraryfile=KFOLD_PATH, transform=None,mult=2, s=10, shuffle=False, set='', test_fold=None, val_fold=None):\n",
    "        path_dir = DATA_PATH\n",
    "        lib = pd.DataFrame(pd.read_csv(libraryfile, usecols=[\n",
    "            'Case_ID', 'WSI_Dir', 'label_desc', 'label_id', f'fold'\n",
    "        ]))\n",
    "        lib.dropna(inplace=True)\n",
    "\n",
    "        allcases = lib['Case_ID'].values.tolist()\n",
    "        allslides = lib['WSI_Dir'].values.tolist()\n",
    "        tar = lib['label_id'].values.tolist()\n",
    "        label_desc = lib['label_desc'].values.tolist()\n",
    "        split = lib[f'fold'].values.tolist()\n",
    "        \n",
    "        train_idx, val_idx, test_idx = get_split_indices(lib, test_fold, val_fold)\n",
    "        if set == 'train':\n",
    "            indices = train_idx\n",
    "            print(f\"##--Targets ==> {len(tar)} | {tar.count(0)} | {tar.count(1)} --##\")\n",
    "            thresh_tiles = 4\n",
    "        elif set == 'valid':\n",
    "            indices = val_idx\n",
    "            print(f\"##--Val Split ==> {len(indices)} Slides\")\n",
    "            thresh_tiles = 4\n",
    "        elif set == 'test':\n",
    "            indices = test_idx\n",
    "            print(f\"##--Test Split ==> {len(indices)} Slides\")\n",
    "            thresh_tiles = 4\n",
    "        else:\n",
    "            raise ValueError(\"Invalid set_type. Must be 'train', 'valid', or 'test'.\")\n",
    "\n",
    "        cases = []\n",
    "        tiles = []\n",
    "        ntiles = []\n",
    "        slideIDX = []\n",
    "        targetIDX = []\n",
    "        targets = []\n",
    "        label_desciption = []\n",
    "        slides = []\n",
    "\n",
    "        j = 0\n",
    "        for i in indices:\n",
    "            path = os.path.join(path_dir, str(allslides[i]))\n",
    "            slide_label = int(tar[i])\n",
    "            if os.path.exists(path):\n",
    "                Max_Patches = 10\n",
    "                t = [\n",
    "                    os.path.join(path, f)\n",
    "                    for f in os.listdir(path)\n",
    "                    if f.endswith('.png')\n",
    "                ]\n",
    "                if len(t) >= thresh_tiles:\n",
    "                    cases.append(allcases[i])\n",
    "                    slides.append(allslides[i])\n",
    "                    tiles.extend(t)\n",
    "                    ntiles.append(len(t))\n",
    "                    slideIDX.extend([j]*len(t))\n",
    "                    targetIDX.extend([slide_label]*len(t))\n",
    "                    targets.append(slide_label)\n",
    "                    label_desciption.append(label_desc[i])\n",
    "                    j += 1\n",
    "\n",
    "        self.slideIDX = slideIDX\n",
    "        self.ntiles = ntiles\n",
    "        self.tiles = tiles\n",
    "        self.targets = targets\n",
    "        self.label_desc = label_desciption\n",
    "        self.slides = slides\n",
    "        self.cases = cases\n",
    "        self.transform = transform\n",
    "        self.mult = mult\n",
    "        self.s = s\n",
    "        self.mode = None\n",
    "        self.shuffle = shuffle\n",
    "        self.targetIDX = targetIDX\n",
    "\n",
    "        print('-------------------------')\n",
    "        print('Number of Slides: {}'.format(len(slides)))\n",
    "        print('Number of tiles: {}'.format(len(tiles)))\n",
    "        if len(ntiles) > 0:\n",
    "            print('Max tiles: ', max(ntiles))\n",
    "            print('Min tiles: ', min(ntiles))\n",
    "            print('Average tiles: ', np.mean(ntiles))\n",
    "        print('nonMSI: ', targets.count(0))\n",
    "        print('MSI: ', targets.count(1))\n",
    "\n",
    "    def setmode(self, mode):\n",
    "        \"\"\"Set self.mode to 1 or 2 depending on training iteration usage.\"\"\"\n",
    "        self.mode = mode\n",
    "\n",
    "    def maketraindata(self, idxs):\n",
    "        self.t_data = [(self.slideIDX[x], self.tiles[x], self.targets[self.slideIDX[x]]) \n",
    "                       for x in idxs]\n",
    "\n",
    "    def shuffletraindata(self):\n",
    "        self.t_data = random.sample(self.t_data, len(self.t_data))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        If mode=1, we sample from the full tile list; if mode=2, from t_data.\n",
    "        Each tile is loaded, optionally transformed, which includes FiveCrop.\n",
    "        So the transform outputs shape [5, 3, 224, 224].\n",
    "        \"\"\"\n",
    "        if self.mode == 1:\n",
    "            tile_path = self.tiles[index]\n",
    "            slide_idx = self.slideIDX[index]\n",
    "            img = Image.open(tile_path).convert('RGB')\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)  # => shape (5, 3, 224, 224)\n",
    "            target = self.targets[slide_idx]\n",
    "            return img, target, slide_idx\n",
    "\n",
    "        elif self.mode == 2:\n",
    "            slideIDX, tile_path, target = self.t_data[index]\n",
    "            img = Image.open(tile_path).convert('RGB')\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)  # => shape (5, 3, 224, 224)\n",
    "            return img, target, slideIDX\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.mode == 1:\n",
    "            return len(self.tiles)\n",
    "        elif self.mode == 2:\n",
    "            return len(self.t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##--Targets ==> 405 | 344 | 61 --##\n",
      "-------------------------\n",
      "Number of Slides: 211\n",
      "Number of tiles: 131716\n",
      "Max tiles:  1875\n",
      "Min tiles:  16\n",
      "Average tiles:  624.2464454976304\n",
      "nonMSI:  178\n",
      "MSI:  33\n",
      "##--Val Split ==> 94 Slides\n",
      "-------------------------\n",
      "Number of Slides: 94\n",
      "Number of tiles: 55618\n",
      "Max tiles:  1682\n",
      "Min tiles:  6\n",
      "Average tiles:  591.6808510638298\n",
      "nonMSI:  81\n",
      "MSI:  13\n",
      "##--Test Split ==> 100 Slides\n",
      "-------------------------\n",
      "Number of Slides: 100\n",
      "Number of tiles: 55849\n",
      "Max tiles:  1942\n",
      "Min tiles:  30\n",
      "Average tiles:  558.49\n",
      "nonMSI:  85\n",
      "MSI:  15\n",
      "Number of slides: 211 | Number of tiles: 131716\n",
      "Number of randk1: 66011\n",
      "Train Epoch: [  1/  4] Batch:   1/129, Loss: 1.3619, acc: 73.44%, xent: 0.1702, conf: 1.0372, slide: 0.1544\n",
      "Train Epoch: [  1/  4] Batch: 101/129, Loss: 0.4907, acc: 83.99%, xent: 0.2563, conf: 0.1903, slide: 0.0002\n",
      "Training Epoch: [1/4]\tLoss: 0.4645\tAccuracy:  84%\n",
      "Inference\tEpoch: [  1/  4]\tBatch: [  1/258]\tValidation: Loss: -2.0527, acc: 94.53%\n",
      "Inference\tEpoch: [  1/  4]\tBatch: [101/258]\tValidation: Loss: -2.1108, acc: 83.44%\n",
      "Inference\tEpoch: [  1/  4]\tBatch: [201/258]\tValidation: Loss: -2.1420, acc: 84.86%\n",
      "Confidence\tMin: 0.3742\tAverage: 0.8833\tMax: 0.9999\n",
      "Number of topk found: 33162\n",
      "Number of topk1: 33162\n",
      "Number of randk2: 66011\n",
      "Train Epoch: [  2/  4] Batch:   1/129, Loss: 0.4239, acc: 83.59%, xent: 0.2880, conf: 0.1065, slide: 0.0294\n",
      "Train Epoch: [  2/  4] Batch: 101/129, Loss: 0.3543, acc: 87.31%, xent: 0.2197, conf: 0.1060, slide: 0.0005\n",
      "Training Epoch: [2/4]\tLoss: 0.3458\tAccuracy:  87%\n",
      "Inference\tEpoch: [  2/  4]\tBatch: [  1/258]\tValidation: Loss: -3.3345, acc: 98.24%\n",
      "Inference\tEpoch: [  2/  4]\tBatch: [101/258]\tValidation: Loss: -2.7276, acc: 85.34%\n",
      "Inference\tEpoch: [  2/  4]\tBatch: [201/258]\tValidation: Loss: -2.8135, acc: 86.39%\n",
      "Confidence\tMin: 0.3439\tAverage: 0.9435\tMax: 1.0000\n",
      "Number of topk found: 33162\n",
      "Number of topk from second update: 33162\n",
      " these two should be the same 33162 == 33162\n",
      "Overall topk after 2 iterations: 66206\n",
      "Number of randk k 66011\n",
      "Number of randk and topk combined  99081\n",
      "Train Epoch: [  3/  4] Batch:   1/194, Loss: 0.3202, acc: 89.06%, xent: 0.2065, conf: 0.0906, slide: 0.0232\n",
      "Train Epoch: [  3/  4] Batch: 101/194, Loss: 0.3043, acc: 89.34%, xent: 0.1900, conf: 0.0864, slide: 0.0002\n",
      "Training\tEpoch: [3/4]\tLoss: 0.2938\tAccuracy:  89\n",
      "Inference\tEpoch: [  3/  4]\tBatch: [  1/194]\tValidation: Loss: -3.2183, acc: 89.45%\n",
      "Inference\tEpoch: [  3/  4]\tBatch: [101/194]\tValidation: Loss: -3.2096, acc: 90.19%\n",
      "Confidence\tMin: 0.0259\tAverage: 0.9329\tMax: 1.0000\n",
      "Number of topk 82642 in epoch 2\n",
      "Inference\tEpoch: [  3/  4]\tBatch: [  1/109]\tValidation: Loss: -3.5577, acc: 98.83%\n",
      "Inference\tEpoch: [  3/  4]\tBatch: [101/109]\tValidation: Loss: -2.8232, acc: 89.59%\n",
      "Confidence\tMin: 0.5544\tAverage: 0.9380\tMax: 1.0000\n",
      "\n",
      "----------------------Validation Results -------------------------------------\n",
      "F1-scores (Val): MV=0.463  AVG=0.463  MAX=0.463  top10=0.463\n",
      "Balanced Acc (Val): MV=0.500  AVG=0.500  MAX=0.500  top10=0.500\n",
      "AUC-scores (Val): AVG=0.456  MAX=0.416  top10=0.439\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Saved checkpoint_best_F1.pth\n",
      "Saved checkpoint_best_AUC.pth\n",
      "Number of randk k 66011\n",
      "Number of randk and topk combined  107198\n",
      "Train Epoch: [  4/  4] Batch:   1/210, Loss: 0.2473, acc: 92.97%, xent: 0.1348, conf: 0.0802, slide: 0.0323\n",
      "Train Epoch: [  4/  4] Batch: 101/210, Loss: 0.2632, acc: 90.79%, xent: 0.1644, conf: 0.0729, slide: 0.0003\n",
      "Train Epoch: [  4/  4] Batch: 201/210, Loss: 0.2563, acc: 91.13%, xent: 0.1607, conf: 0.0696, slide: 0.0001\n",
      "Training\tEpoch: [4/4]\tLoss: 0.2553\tAccuracy:  91\n",
      "Inference\tEpoch: [  4/  4]\tBatch: [  1/109]\tValidation: Loss: -2.8409, acc: 93.16%\n",
      "Inference\tEpoch: [  4/  4]\tBatch: [101/109]\tValidation: Loss: -3.0015, acc: 89.91%\n",
      "Confidence\tMin: 0.4531\tAverage: 0.9405\tMax: 1.0000\n",
      "\n",
      "----------------------Validation Results -------------------------------------\n",
      "F1-scores (Val): MV=0.463  AVG=0.463  MAX=0.463  top10=0.463\n",
      "Balanced Acc (Val): MV=0.500  AVG=0.500  MAX=0.500  top10=0.500\n",
      "AUC-scores (Val): AVG=0.602  MAX=0.543  top10=0.538\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Saved checkpoint_best_AUC.pth\n",
      "Inference\tEpoch: [  4/  4]\tBatch: [  1/110]\tValidation: Loss: -1.6403, acc: 78.52%\n",
      "Inference\tEpoch: [  4/  4]\tBatch: [101/110]\tValidation: Loss: -2.2804, acc: 80.76%\n",
      "Confidence\tMin: 0.4812\tAverage: 0.9326\tMax: 1.0000\n",
      "Predicted Tiles: 55849, classes: 2, total targets: 100\n",
      "\n",
      "----------------------Test Set Results-------------------------------\n",
      "Test F1-scores: MV=0.457, AVG=0.457, MAX=0.622, top10=0.518\n",
      "Test Balanced Acc: MV=0.494, AVG=0.494, MAX=0.594, top10=0.527\n",
      "Test AUC-scores: AVG=0.744, MAX=0.741, top10=0.733\n",
      "Confusion Matrix (Average Predictions):\n",
      "[[84  1]\n",
      " [15  0]]\n",
      "Classification Report (Average Predictions):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91        85\n",
      "           1       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.84       100\n",
      "   macro avg       0.42      0.49      0.46       100\n",
      "weighted avg       0.72      0.84      0.78       100\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "..............Test set done ...............\n",
      "Done setting up 5-crop pipeline for fold  1\n",
      "##--Targets ==> 405 | 344 | 61 --##\n",
      "-------------------------\n",
      "Number of Slides: 200\n",
      "Number of tiles: 119899\n",
      "Max tiles:  1942\n",
      "Min tiles:  18\n",
      "Average tiles:  599.495\n",
      "nonMSI:  172\n",
      "MSI:  28\n",
      "##--Val Split ==> 111 Slides\n",
      "-------------------------\n",
      "Number of Slides: 111\n",
      "Number of tiles: 67666\n",
      "Max tiles:  1849\n",
      "Min tiles:  16\n",
      "Average tiles:  609.6036036036036\n",
      "nonMSI:  91\n",
      "MSI:  20\n",
      "##--Test Split ==> 94 Slides\n",
      "-------------------------\n",
      "Number of Slides: 94\n",
      "Number of tiles: 55618\n",
      "Max tiles:  1682\n",
      "Min tiles:  6\n",
      "Average tiles:  591.6808510638298\n",
      "nonMSI:  81\n",
      "MSI:  13\n",
      "Number of slides: 200 | Number of tiles: 119899\n",
      "Number of randk1: 60105\n",
      "Train Epoch: [  1/  4] Batch:   1/118, Loss: 1.5945, acc: 36.52%, xent: 0.1838, conf: 1.2200, slide: 0.1907\n",
      "Train Epoch: [  1/  4] Batch: 101/118, Loss: 0.5069, acc: 82.84%, xent: 0.2439, conf: 0.2117, slide: 0.0003\n",
      "Training Epoch: [1/4]\tLoss: 0.4871\tAccuracy:  83%\n",
      "Inference\tEpoch: [  1/  4]\tBatch: [  1/235]\tValidation: Loss: -1.4605, acc: 78.71%\n",
      "Inference\tEpoch: [  1/  4]\tBatch: [101/235]\tValidation: Loss: -2.4236, acc: 87.39%\n",
      "Inference\tEpoch: [  1/  4]\tBatch: [201/235]\tValidation: Loss: -2.2740, acc: 86.13%\n",
      "Confidence\tMin: 0.3679\tAverage: 0.9085\tMax: 1.0000\n",
      "Number of topk found: 30201\n",
      "Number of topk1: 30201\n",
      "Number of randk2: 60105\n",
      "Train Epoch: [  2/  4] Batch:   1/118, Loss: 0.3710, acc: 87.11%, xent: 0.2334, conf: 0.1068, slide: 0.0308\n",
      "Train Epoch: [  2/  4] Batch: 101/118, Loss: 0.3286, acc: 88.52%, xent: 0.2023, conf: 0.0993, slide: 0.0003\n",
      "Training Epoch: [2/4]\tLoss: 0.3247\tAccuracy:  88%\n",
      "Inference\tEpoch: [  2/  4]\tBatch: [  1/235]\tValidation: Loss: -1.5839, acc: 78.71%\n",
      "Inference\tEpoch: [  2/  4]\tBatch: [101/235]\tValidation: Loss: -2.4756, acc: 87.65%\n",
      "Inference\tEpoch: [  2/  4]\tBatch: [201/235]\tValidation: Loss: -2.5380, acc: 87.42%\n",
      "Confidence\tMin: 0.3908\tAverage: 0.9188\tMax: 1.0000\n",
      "Number of topk found: 30201\n",
      "Number of topk from second update: 30201\n",
      " these two should be the same 30201 == 30201\n",
      "Overall topk after 2 iterations: 60316\n",
      "Number of randk k 60105\n",
      "Number of randk and topk combined  90130\n",
      "Train Epoch: [  3/  4] Batch:   1/177, Loss: 0.3003, acc: 89.26%, xent: 0.1842, conf: 0.0964, slide: 0.0197\n",
      "Train Epoch: [  3/  4] Batch: 101/177, Loss: 0.2859, acc: 90.04%, xent: 0.1778, conf: 0.0817, slide: 0.0002\n",
      "Training\tEpoch: [3/4]\tLoss: 0.2795\tAccuracy:  90\n",
      "Inference\tEpoch: [  3/  4]\tBatch: [  1/177]\tValidation: Loss: -2.5797, acc: 89.65%\n",
      "Inference\tEpoch: [  3/  4]\tBatch: [101/177]\tValidation: Loss: -2.6189, acc: 89.67%\n",
      "Confidence\tMin: 0.3042\tAverage: 0.9149\tMax: 1.0000\n",
      "Number of topk 75345 in epoch 2\n",
      "Inference\tEpoch: [  3/  4]\tBatch: [  1/133]\tValidation: Loss: -1.7156, acc: 92.19%\n",
      "Inference\tEpoch: [  3/  4]\tBatch: [101/133]\tValidation: Loss: -1.4349, acc: 74.85%\n",
      "Confidence\tMin: 0.4196\tAverage: 0.9149\tMax: 1.0000\n",
      "\n",
      "----------------------Validation Results -------------------------------------\n",
      "F1-scores (Val): MV=0.450  AVG=0.450  MAX=0.450  top10=0.450\n",
      "Balanced Acc (Val): MV=0.500  AVG=0.500  MAX=0.500  top10=0.500\n",
      "AUC-scores (Val): AVG=0.677  MAX=0.659  top10=0.626\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Saved checkpoint_best_F1.pth\n",
      "Saved checkpoint_best_AUC.pth\n",
      "Number of randk k 60105\n",
      "Number of randk and topk combined  97679\n",
      "Train Epoch: [  4/  4] Batch:   1/191, Loss: 0.2425, acc: 91.60%, xent: 0.1398, conf: 0.0721, slide: 0.0306\n",
      "Train Epoch: [  4/  4] Batch: 101/191, Loss: 0.2556, acc: 91.12%, xent: 0.1597, conf: 0.0697, slide: 0.0002\n",
      "Training\tEpoch: [4/4]\tLoss: 0.2481\tAccuracy:  91\n",
      "Inference\tEpoch: [  4/  4]\tBatch: [  1/133]\tValidation: Loss: -2.7822, acc: 94.53%\n",
      "Inference\tEpoch: [  4/  4]\tBatch: [101/133]\tValidation: Loss: -2.1731, acc: 76.97%\n",
      "Confidence\tMin: 0.5521\tAverage: 0.9605\tMax: 1.0000\n",
      "\n",
      "----------------------Validation Results -------------------------------------\n",
      "F1-scores (Val): MV=0.546  AVG=0.546  MAX=0.495  top10=0.495\n",
      "Balanced Acc (Val): MV=0.550  AVG=0.550  MAX=0.520  top10=0.520\n",
      "AUC-scores (Val): AVG=0.763  MAX=0.768  top10=0.736\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Saved checkpoint_best_F1.pth\n",
      "Saved checkpoint_best_AUC.pth\n",
      "Inference\tEpoch: [  4/  4]\tBatch: [  1/109]\tValidation: Loss: -4.0774, acc: 97.27%\n",
      "Inference\tEpoch: [  4/  4]\tBatch: [101/109]\tValidation: Loss: -3.3884, acc: 90.09%\n",
      "Confidence\tMin: 0.4703\tAverage: 0.9612\tMax: 1.0000\n",
      "Predicted Tiles: 55618, classes: 2, total targets: 94\n",
      "\n",
      "----------------------Test Set Results-------------------------------\n",
      "Test F1-scores: MV=0.463, AVG=0.463, MAX=0.460, top10=0.460\n",
      "Test Balanced Acc: MV=0.500, AVG=0.500, MAX=0.494, top10=0.494\n",
      "Test AUC-scores: AVG=0.621, MAX=0.594, top10=0.556\n",
      "Confusion Matrix (Average Predictions):\n",
      "[[81  0]\n",
      " [13  0]]\n",
      "Classification Report (Average Predictions):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93        81\n",
      "           1       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.86        94\n",
      "   macro avg       0.43      0.50      0.46        94\n",
      "weighted avg       0.74      0.86      0.80        94\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "..............Test set done ...............\n",
      "Done setting up 5-crop pipeline for fold  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\tcga\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Anaconda3\\envs\\tcga\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Anaconda3\\envs\\tcga\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##--Targets ==> 405 | 344 | 61 --##\n",
      "-------------------------\n",
      "Number of Slides: 194\n",
      "Number of tiles: 111467\n",
      "Max tiles:  1942\n",
      "Min tiles:  6\n",
      "Average tiles:  574.5721649484536\n",
      "nonMSI:  166\n",
      "MSI:  28\n",
      "##--Val Split ==> 100 Slides\n",
      "-------------------------\n",
      "Number of Slides: 100\n",
      "Number of tiles: 64050\n",
      "Max tiles:  1875\n",
      "Min tiles:  18\n",
      "Average tiles:  640.5\n",
      "nonMSI:  87\n",
      "MSI:  13\n",
      "##--Test Split ==> 111 Slides\n",
      "-------------------------\n",
      "Number of Slides: 111\n",
      "Number of tiles: 67666\n",
      "Max tiles:  1849\n",
      "Min tiles:  16\n",
      "Average tiles:  609.6036036036036\n",
      "nonMSI:  91\n",
      "MSI:  20\n",
      "Number of slides: 194 | Number of tiles: 111467\n",
      "Number of randk1: 55885\n",
      "Train Epoch: [  1/  4] Batch:   1/110, Loss: 1.5152, acc: 19.53%, xent: 0.2657, conf: 0.9665, slide: 0.2831\n",
      "Train Epoch: [  1/  4] Batch: 101/110, Loss: 0.4563, acc: 84.67%, xent: 0.2184, conf: 0.1917, slide: 0.0002\n",
      "Training Epoch: [1/4]\tLoss: 0.4459\tAccuracy:  85%\n",
      "Inference\tEpoch: [  1/  4]\tBatch: [  1/218]\tValidation: Loss: -1.2871, acc: 78.32%\n",
      "Inference\tEpoch: [  1/  4]\tBatch: [101/218]\tValidation: Loss: -1.9556, acc: 86.91%\n",
      "Inference\tEpoch: [  1/  4]\tBatch: [201/218]\tValidation: Loss: -1.8985, acc: 88.78%\n",
      "Confidence\tMin: 0.4257\tAverage: 0.9223\tMax: 1.0000\n",
      "Number of topk found: 28089\n",
      "Number of topk1: 28089\n",
      "Number of randk2: 55885\n",
      "Train Epoch: [  2/  4] Batch:   1/110, Loss: 0.2934, acc: 90.62%, xent: 0.1686, conf: 0.0961, slide: 0.0287\n",
      "Train Epoch: [  2/  4] Batch: 101/110, Loss: 0.2963, acc: 89.96%, xent: 0.1829, conf: 0.0879, slide: 0.0003\n",
      "Training Epoch: [2/4]\tLoss: 0.2943\tAccuracy:  90%\n",
      "Inference\tEpoch: [  2/  4]\tBatch: [  1/218]\tValidation: Loss: -1.2103, acc: 80.47%\n",
      "Inference\tEpoch: [  2/  4]\tBatch: [101/218]\tValidation: Loss: -1.6755, acc: 86.24%\n",
      "Inference\tEpoch: [  2/  4]\tBatch: [201/218]\tValidation: Loss: -1.8395, acc: 88.81%\n",
      "Confidence\tMin: 0.3373\tAverage: 0.9134\tMax: 1.0000\n",
      "Number of topk found: 28089\n",
      "Number of topk from second update: 28089\n",
      " these two should be the same 28089 == 28089\n",
      "Overall topk after 2 iterations: 56081\n",
      "Number of randk k 55885\n",
      "Number of randk and topk combined  83797\n",
      "Train Epoch: [  3/  4] Batch:   1/164, Loss: 0.2501, acc: 91.99%, xent: 0.1561, conf: 0.0688, slide: 0.0252\n",
      "Train Epoch: [  3/  4] Batch: 101/164, Loss: 0.2602, acc: 91.17%, xent: 0.1623, conf: 0.0738, slide: 0.0002\n",
      "Training\tEpoch: [3/4]\tLoss: 0.2534\tAccuracy:  91\n",
      "Inference\tEpoch: [  3/  4]\tBatch: [  1/164]\tValidation: Loss: -2.5185, acc: 92.58%\n",
      "Inference\tEpoch: [  3/  4]\tBatch: [101/164]\tValidation: Loss: -2.5934, acc: 91.87%\n",
      "Confidence\tMin: 0.5681\tAverage: 0.9519\tMax: 1.0000\n",
      "Number of topk 70003 in epoch 2\n",
      "Inference\tEpoch: [  3/  4]\tBatch: [  1/126]\tValidation: Loss: -2.7737, acc: 98.63%\n",
      "Inference\tEpoch: [  3/  4]\tBatch: [101/126]\tValidation: Loss: -1.3687, acc: 82.12%\n",
      "Confidence\tMin: 0.6012\tAverage: 0.9490\tMax: 1.0000\n",
      "\n",
      "----------------------Validation Results -------------------------------------\n",
      "F1-scores (Val): MV=0.604  AVG=0.660  MAX=0.738  top10=0.756\n",
      "Balanced Acc (Val): MV=0.577  AVG=0.615  MAX=0.687  top10=0.692\n",
      "AUC-scores (Val): AVG=0.671  MAX=0.759  top10=0.735\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Saved checkpoint_best_F1.pth\n",
      "Saved checkpoint_best_AUC.pth\n",
      "Number of randk k 55885\n",
      "Number of randk and topk combined  90905\n",
      "Train Epoch: [  4/  4] Batch:   1/178, Loss: 0.3076, acc: 90.62%, xent: 0.2072, conf: 0.0550, slide: 0.0454\n",
      "Train Epoch: [  4/  4] Batch: 101/178, Loss: 0.2273, acc: 92.20%, xent: 0.1410, conf: 0.0622, slide: 0.0001\n",
      "Training\tEpoch: [4/4]\tLoss: 0.2213\tAccuracy:  92\n",
      "Inference\tEpoch: [  4/  4]\tBatch: [  1/126]\tValidation: Loss: -4.0137, acc: 98.63%\n",
      "Inference\tEpoch: [  4/  4]\tBatch: [101/126]\tValidation: Loss: -2.0298, acc: 82.42%\n",
      "Confidence\tMin: 0.4277\tAverage: 0.9727\tMax: 1.0000\n",
      "\n",
      "----------------------Validation Results -------------------------------------\n",
      "F1-scores (Val): MV=0.465  AVG=0.465  MAX=0.465  top10=0.465\n",
      "Balanced Acc (Val): MV=0.500  AVG=0.500  MAX=0.500  top10=0.500\n",
      "AUC-scores (Val): AVG=0.666  MAX=0.705  top10=0.713\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Inference\tEpoch: [  4/  4]\tBatch: [  1/133]\tValidation: Loss: -1.8673, acc: 92.97%\n",
      "Inference\tEpoch: [  4/  4]\tBatch: [101/133]\tValidation: Loss: -1.2488, acc: 76.60%\n",
      "Confidence\tMin: 0.5408\tAverage: 0.9506\tMax: 1.0000\n",
      "Predicted Tiles: 67666, classes: 2, total targets: 111\n",
      "\n",
      "----------------------Test Set Results-------------------------------\n",
      "Test F1-scores: MV=0.500, AVG=0.495, MAX=0.580, top10=0.580\n",
      "Test Balanced Acc: MV=0.525, AVG=0.520, MAX=0.570, top10=0.570\n",
      "Test AUC-scores: AVG=0.735, MAX=0.707, top10=0.709\n",
      "Confusion Matrix (Average Predictions):\n",
      "[[90  1]\n",
      " [19  1]]\n",
      "Classification Report (Average Predictions):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90        91\n",
      "           1       0.50      0.05      0.09        20\n",
      "\n",
      "    accuracy                           0.82       111\n",
      "   macro avg       0.66      0.52      0.50       111\n",
      "weighted avg       0.77      0.82      0.75       111\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "..............Test set done ...............\n",
      "Done setting up 5-crop pipeline for fold  3\n",
      "##--Targets ==> 405 | 344 | 61 --##\n",
      "-------------------------\n",
      "Number of Slides: 205\n",
      "Number of tiles: 123284\n",
      "Max tiles:  1849\n",
      "Min tiles:  6\n",
      "Average tiles:  601.3853658536585\n",
      "nonMSI:  172\n",
      "MSI:  33\n",
      "##--Val Split ==> 100 Slides\n",
      "-------------------------\n",
      "Number of Slides: 100\n",
      "Number of tiles: 55849\n",
      "Max tiles:  1942\n",
      "Min tiles:  30\n",
      "Average tiles:  558.49\n",
      "nonMSI:  85\n",
      "MSI:  15\n",
      "##--Test Split ==> 100 Slides\n",
      "-------------------------\n",
      "Number of Slides: 100\n",
      "Number of tiles: 64050\n",
      "Max tiles:  1875\n",
      "Min tiles:  18\n",
      "Average tiles:  640.5\n",
      "nonMSI:  87\n",
      "MSI:  13\n",
      "Number of slides: 205 | Number of tiles: 123284\n",
      "Number of randk1: 61791\n",
      "Train Epoch: [  1/  4] Batch:   1/121, Loss: 1.4473, acc: 43.36%, xent: 0.2234, conf: 0.9980, slide: 0.2259\n",
      "Train Epoch: [  1/  4] Batch: 101/121, Loss: 0.4820, acc: 83.84%, xent: 0.2374, conf: 0.2006, slide: 0.0003\n",
      "Training Epoch: [1/4]\tLoss: 0.4603\tAccuracy:  84%\n",
      "Inference\tEpoch: [  1/  4]\tBatch: [  1/241]\tValidation: Loss: -3.2887, acc: 100.00%\n",
      "Inference\tEpoch: [  1/  4]\tBatch: [101/241]\tValidation: Loss: -2.5698, acc: 92.22%\n",
      "Inference\tEpoch: [  1/  4]\tBatch: [201/241]\tValidation: Loss: -2.4062, acc: 88.56%\n",
      "Confidence\tMin: 0.4781\tAverage: 0.9058\tMax: 1.0000\n",
      "Number of topk found: 31050\n",
      "Number of topk1: 31050\n",
      "Number of randk2: 61791\n",
      "Train Epoch: [  2/  4] Batch:   1/121, Loss: 0.3607, acc: 86.72%, xent: 0.2327, conf: 0.1053, slide: 0.0226\n",
      "Train Epoch: [  2/  4] Batch: 101/121, Loss: 0.3228, acc: 88.78%, xent: 0.2002, conf: 0.0963, slide: 0.0003\n",
      "Training Epoch: [2/4]\tLoss: 0.3172\tAccuracy:  88%\n",
      "Inference\tEpoch: [  2/  4]\tBatch: [  1/241]\tValidation: Loss: -3.6762, acc: 100.00%\n",
      "Inference\tEpoch: [  2/  4]\tBatch: [101/241]\tValidation: Loss: -2.6532, acc: 92.64%\n",
      "Inference\tEpoch: [  2/  4]\tBatch: [201/241]\tValidation: Loss: -2.5438, acc: 89.63%\n",
      "Confidence\tMin: 0.5465\tAverage: 0.9037\tMax: 1.0000\n",
      "Number of topk found: 31050\n",
      "Number of topk from second update: 31050\n",
      " these two should be the same 31050 == 31050\n",
      "Overall topk after 2 iterations: 61991\n",
      "Number of randk k 61791\n",
      "Number of randk and topk combined  92618\n",
      "Train Epoch: [  3/  4] Batch:   1/181, Loss: 0.2915, acc: 90.23%, xent: 0.1886, conf: 0.0726, slide: 0.0302\n",
      "Train Epoch: [  3/  4] Batch: 101/181, Loss: 0.2802, acc: 90.25%, xent: 0.1740, conf: 0.0813, slide: 0.0002\n",
      "Training\tEpoch: [3/4]\tLoss: 0.2697\tAccuracy:  90\n",
      "Inference\tEpoch: [  3/  4]\tBatch: [  1/181]\tValidation: Loss: -3.2678, acc: 90.82%\n",
      "Inference\tEpoch: [  3/  4]\tBatch: [101/181]\tValidation: Loss: -3.2644, acc: 91.18%\n",
      "Confidence\tMin: 0.3674\tAverage: 0.9389\tMax: 1.0000\n",
      "Number of topk 77337 in epoch 2\n",
      "Inference\tEpoch: [  3/  4]\tBatch: [  1/110]\tValidation: Loss: -1.6403, acc: 78.32%\n",
      "Inference\tEpoch: [  3/  4]\tBatch: [101/110]\tValidation: Loss: -2.1800, acc: 81.40%\n",
      "Confidence\tMin: 0.3397\tAverage: 0.9254\tMax: 1.0000\n",
      "\n",
      "----------------------Validation Results -------------------------------------\n",
      "F1-scores (Val): MV=0.524  AVG=0.524  MAX=0.632  top10=0.667\n",
      "Balanced Acc (Val): MV=0.533  AVG=0.533  MAX=0.610  top10=0.627\n",
      "AUC-scores (Val): AVG=0.833  MAX=0.766  top10=0.794\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Saved checkpoint_best_F1.pth\n",
      "Saved checkpoint_best_AUC.pth\n",
      "Number of randk k 61791\n",
      "Number of randk and topk combined  100307\n",
      "Train Epoch: [  4/  4] Batch:   1/196, Loss: 0.1904, acc: 93.75%, xent: 0.1161, conf: 0.0587, slide: 0.0155\n",
      "Train Epoch: [  4/  4] Batch: 101/196, Loss: 0.2380, acc: 91.90%, xent: 0.1489, conf: 0.0648, slide: 0.0002\n",
      "Training\tEpoch: [4/4]\tLoss: 0.2303\tAccuracy:  92\n",
      "Inference\tEpoch: [  4/  4]\tBatch: [  1/110]\tValidation: Loss: -2.2172, acc: 77.34%\n",
      "Inference\tEpoch: [  4/  4]\tBatch: [101/110]\tValidation: Loss: -2.1902, acc: 78.56%\n",
      "Confidence\tMin: 0.3426\tAverage: 0.9345\tMax: 1.0000\n",
      "\n",
      "----------------------Validation Results -------------------------------------\n",
      "F1-scores (Val): MV=0.582  AVG=0.582  MAX=0.707  top10=0.667\n",
      "Balanced Acc (Val): MV=0.567  AVG=0.567  MAX=0.661  top10=0.627\n",
      "AUC-scores (Val): AVG=0.794  MAX=0.765  top10=0.786\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Saved checkpoint_best_F1.pth\n",
      "Inference\tEpoch: [  4/  4]\tBatch: [  1/126]\tValidation: Loss: -2.2775, acc: 93.16%\n",
      "Inference\tEpoch: [  4/  4]\tBatch: [101/126]\tValidation: Loss: -1.9417, acc: 79.73%\n",
      "Confidence\tMin: 0.3119\tAverage: 0.9271\tMax: 1.0000\n",
      "Predicted Tiles: 64050, classes: 2, total targets: 100\n",
      "\n",
      "----------------------Test Set Results-------------------------------\n",
      "Test F1-scores: MV=0.462, AVG=0.462, MAX=0.518, top10=0.518\n",
      "Test Balanced Acc: MV=0.494, AVG=0.494, MAX=0.521, top10=0.521\n",
      "Test AUC-scores: AVG=0.644, MAX=0.653, top10=0.647\n",
      "Confusion Matrix (Average Predictions):\n",
      "[[86  1]\n",
      " [13  0]]\n",
      "Classification Report (Average Predictions):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92        87\n",
      "           1       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.86       100\n",
      "   macro avg       0.43      0.49      0.46       100\n",
      "weighted avg       0.76      0.86      0.80       100\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "..............Test set done ...............\n",
      "Done setting up 5-crop pipeline for fold  4\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "#                               Main Training                                 #\n",
    "###############################################################################\n",
    "def run_train_step(epoch,data_indices, dataset,loader,model, criterion, optimizer, scheduler, lmbda,args):\n",
    "    \"\"\"\n",
    "    1) Sets the dataset mode\n",
    "    2) Loads the selected data indices (tiles) into the dataset e.g random or topk\n",
    "    3) Trains for one epoch\n",
    "    4) Logs the result\n",
    "    \"\"\"\n",
    "    # 1) Prepare data\n",
    "    dataset.setmode(1)\n",
    "    dataset.maketraindata(data_indices)\n",
    "    dataset.shuffletraindata()\n",
    "    dataset.setmode(2)\n",
    "    # 2) Train\n",
    "    loss, acc = train(epoch, loader, model, criterion, optimizer)\n",
    "    # 3) Print & log\n",
    "    print('Training Epoch: [{}/{}]\\tLoss: {:0.4f}\\tAccuracy: {:3d}%'.format(\n",
    "            epoch + 1, args.nepochs, loss, int(acc * 100)))\n",
    "    log_file = os.path.join(args.output, 'train_convergence.csv')\n",
    "    with open(log_file, 'a') as fconv:\n",
    "        fconv.write('{},{:0.4f},{:3d}\\n'.format(epoch, loss, int(acc * 100)))\n",
    "    return loss, acc\n",
    "def update_topk(epoch,data_indices,dataset,loader,model,criterion,topk_list=None,invert=False):\n",
    "    \"\"\"\n",
    "    1) Performs inference on the specified data_indices\n",
    "    2) Computes top_prob = 1 - prob[:, 0] (or some variant)\n",
    "    3) Collects top-50% or top-k% tiles\n",
    "    4) Optionally merges with an existing 'topk_list'\n",
    "    Returns:\n",
    "        updated_topk (list): new or merged topk\n",
    "    \"\"\"\n",
    "    # 1) Inference\n",
    "    dataset.maketraindata(data_indices)\n",
    "    dataset.setmode(1)\n",
    "    trn_probs, _, _, _, trn_conf = inference(epoch, loader, model, criterion)\n",
    "    # shape = [n_tiles, n_classes], and 'trn_conf' is [n_tiles]\n",
    "    # 2) Probability adjustment\n",
    "    trn_probs_conf = np.transpose(trn_probs.transpose() * trn_conf)  # same line as original\n",
    "    top_prob = 1. - trn_probs_conf[:, 0] if not invert else 1. - (1. - trn_probs_conf[:, 0])\n",
    "    # 3) Gather topk\n",
    "    slide_idx = [dataset.slideIDX[item] for item in data_indices]\n",
    "    local_topk = Aggregation.get_topKtraining(np.array(slide_idx), top_prob, args.k)\n",
    "    local_topk = np.array(local_topk, dtype='int64')\n",
    "    # Convert from local index to the overall dataset index\n",
    "    local_topk = [data_indices[item] for item in local_topk]\n",
    "    print(f'Number of topk found: {len(local_topk)}')\n",
    "    # 4) Merge with any existing topk\n",
    "    if topk_list is None:\n",
    "        updated_topk = local_topk\n",
    "    else:\n",
    "        updated_topk = list(set(topk_list + local_topk))\n",
    "    return updated_topk\n",
    "\n",
    "class StackAndNormalize:\n",
    "    def __init__(self, normalize):\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def __call__(self, crops):\n",
    "        return torch.stack([\n",
    "            self.normalize(transforms.ToTensor()(crop)) \n",
    "            for crop in crops\n",
    "        ])\n",
    "\n",
    "def main():\n",
    "    global args, best_auc_v, tr_batch_size, n_slides, best_auc, best_f1_v\n",
    "\n",
    "    config = {\n",
    "        'aggregation_methods': ['average', 'top10', 'max'],\n",
    "        'save_val_tile_csv': True,\n",
    "        'save_test_tile_csv': True,\n",
    "        'save_val_slide_csv': True,\n",
    "        'save_test_slide_csv': True,\n",
    "        'enable_group_avg_df': True,\n",
    "        'enable_plot_metrics': True,\n",
    "        'enable_confusion_matrix': True\n",
    "    }\n",
    "    aggregator = Aggregation(config)\n",
    "    evaluator = Evaluation(config)\n",
    "    \n",
    "    args = parser.parse_args(args=[])\n",
    "    if not os.path.exists(args.output):\n",
    "        os.mkdir(args.output)\n",
    "    args.output = os.path.join(args.output, args.problem)\n",
    "    if not os.path.exists(args.output):\n",
    "        os.mkdir(args.output)\n",
    "    temp_output = args.output\n",
    "# --- 5-crop change: define transforms so we return 5-crops (224×224) for each 512×512 image\n",
    "    normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                        std=[0.1, 0.1, 0.1])\n",
    "    trans = transforms.Compose([\n",
    "        RandomRotation([0, 90, 180, 270]),\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.05),\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
    "        transforms.FiveCrop(224),\n",
    "        StackAndNormalize(normalize)\n",
    "    ])\n",
    "\n",
    "    trans_Valid = transforms.Compose([\n",
    "        transforms.FiveCrop(224),\n",
    "        StackAndNormalize(normalize)])\n",
    "\n",
    "    for fold in range(args.folds):\n",
    "        test_fold = fold + 1\n",
    "        val_fold  = ((fold + 1) % 4) + 1\n",
    "        args.output = os.path.join(temp_output, 'fold' + str(fold + 1))\n",
    "        if not os.path.exists(args.output):\n",
    "            os.mkdir(args.output)\n",
    "        path_fold = args.output\n",
    "\n",
    "        for sets in range(1):\n",
    "            torch.cuda.empty_cache()\n",
    "            args.output = os.path.join(path_fold, 'best' + str(sets))\n",
    "            if not os.path.exists(args.output):\n",
    "                os.mkdir(args.output)\n",
    "            global best_auc_v, best_auc, n_slides, best_loss, best_f1_v, best_Acc, best_ap_v\n",
    "            # reset\n",
    "            best_auc_v = 0\n",
    "            best_auc = 0\n",
    "            n_slides = 0\n",
    "            best_loss = 100000.\n",
    "            best_f1_v = 0.\n",
    "            best_Acc = 0.\n",
    "            best_ap_v = 0.\n",
    "\n",
    "            model = CNN(num_classes=num_classes)\n",
    "            model.cuda()\n",
    "\n",
    "            optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "            scheduler = []\n",
    "            cudnn.benchmark = True\n",
    "            criterion = nn.NLLLoss(ignore_index=-1).cuda()\n",
    "            # --- end 5-crop changes\n",
    "            # Load Data\n",
    "            train_dset = MILdataset(args.data_lib, trans, set='train',  test_fold=test_fold, val_fold=val_fold)\n",
    "            train_loader = torch.utils.data.DataLoader(\n",
    "                train_dset,\n",
    "                batch_size=args.batch_size, shuffle=False,\n",
    "                num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "            val_dset = MILdataset(args.data_lib, trans_Valid, set='valid',  test_fold=test_fold, val_fold=val_fold)\n",
    "            val_loader = torch.utils.data.DataLoader(\n",
    "                val_dset,\n",
    "                batch_size=args.batch_size, shuffle=False,\n",
    "                num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "            test_dset = MILdataset(args.data_lib, trans_Valid, set='test',  test_fold=test_fold, val_fold=val_fold)\n",
    "            test_loader = torch.utils.data.DataLoader(\n",
    "                test_dset,\n",
    "                batch_size=args.batch_size, shuffle=False,\n",
    "                num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "            #  if you wanted to see only dataset distribution and data loaders etc then put continue here\n",
    "            # continue\n",
    "            fconv = open(os.path.join(args.output, 'train_convergence.csv'), 'w')\n",
    "            fconv.write('epoch,loss,accuracy\\n')\n",
    "            fconv.close()\n",
    "\n",
    "            fconv = open(os.path.join(args.output, 'valid_convergence.csv'), 'w')\n",
    "            # We removed sum, median, gmean columns; only keep relevant columns\n",
    "            fconv.write('epoch,tile_loss,tile_acc,best_F1,F1_AVG,F1_Max,F1_T10,best_BAcc,Bacc_AVG,Bacc_Max,Bacc_T10,best_AUC,Avg_AUC,Max_AUC,Top_AUC\\n')\n",
    "            fconv.close()\n",
    "\n",
    "            num_tiles = len(train_dset.slideIDX)\n",
    "            n_slides = len(train_dset.slides)\n",
    "            print(f'Number of slides: {n_slides} | Number of tiles: {num_tiles}')\n",
    "            # 1) Generate initial random selection\n",
    "            r0 = np.random.rand(num_tiles)\n",
    "            randk = aggregator.get_topKtraining(np.array(train_dset.slideIDX), r0, args.r)\n",
    "            print('Number of randk1:', len(randk))\n",
    "            # ---- Epoch 0 Training\n",
    "            loss0, acc0 = run_train_step(epoch=0,data_indices=randk,dataset=train_dset,loader=train_loader,model=model,criterion=criterion,optimizer=optimizer,scheduler=scheduler,lmbda=lmbda,args=args)\n",
    "            # 2) Inference + top prob => local topk\n",
    "            topk = update_topk(epoch=0,data_indices=randk,dataset=train_dset,loader=train_loader,model=model,criterion=criterion,topk_list=None,invert=False)\n",
    "            print('Number of topk1:', len(topk))\n",
    "\n",
    "            # 3) Another random selection\n",
    "            randk2 = aggregator.get_topKtraining(np.array(train_dset.slideIDX), 1 - r0, args.r)\n",
    "            print('Number of randk2:', len(randk2))\n",
    "            # ---- Epoch 1 Training\n",
    "            loss1, acc1 = run_train_step(epoch=1,data_indices=randk2,dataset=train_dset,loader=train_loader,model=model,criterion=criterion,optimizer=optimizer,scheduler=scheduler,lmbda=lmbda,args=args)\n",
    "            # 4) Inference + top prob => local topk, merge with existing topk\n",
    "            temp = update_topk(epoch=1,data_indices=randk2,dataset=train_dset,loader=train_loader,model=model,criterion=criterion,topk_list=None)\n",
    "            print('Number of topk from second update:', len(temp))\n",
    "            print(f' these two should be the same {len(topk)} == {len(temp)}')\n",
    "            topk = list(set(topk + temp))\n",
    "            print('Overall topk after 2 iterations:', len(topk))\n",
    "\n",
    "            # 5) Continue training for remaining epochs\n",
    "            for epoch in range(2, args.nepochs):\n",
    "                randk = list(aggregator.get_topKtraining(np.array(train_dset.slideIDX), \n",
    "                                                    np.random.rand(num_tiles), args.r))\n",
    "                print('Number of randk k', len(randk))\n",
    "                randk = list(set(randk + topk))\n",
    "                print('Number of randk and topk combined ', len(randk))\n",
    "                train_dset.setmode(1)\n",
    "                train_dset.maketraindata(randk)\n",
    "                train_dset.shuffletraindata()\n",
    "                train_dset.setmode(2)\n",
    "                loss, acc = train(epoch, train_loader, model, criterion, optimizer)\n",
    "                print('Training\\tEpoch: [{}/{}]\\tLoss: {:0.4f}\\tAccuracy: {:3d}'\n",
    "                      .format(epoch+1, args.nepochs, loss, int(acc * 100)))\n",
    "\n",
    "                fconv = open(os.path.join(args.output, 'train_convergence.csv'), 'a')\n",
    "                fconv.write('{},{:0.4f},{:3d}\\n'.format(epoch, loss, int(acc * 100)))\n",
    "                fconv.close()\n",
    "\n",
    "                # if there are no of epochs left to train then update topk\n",
    "                if (epoch + 1) < args.nepochs:\n",
    "                    trn_probs, _, _, _, trn_conf = inference(epoch, train_loader, model, criterion)\n",
    "                    trn_probs_conf = np.transpose(trn_probs.transpose() * trn_conf)                \n",
    "                    top_prob = 1.-trn_probs_conf[:,0]\n",
    "                    slide_idx = [train_dset.slideIDX[item] for item in randk]\n",
    "                    local_topk = aggregator.get_topKtraining(np.array(slide_idx), top_prob, args.k)\n",
    "                    local_topk = [randk[item] for item in local_topk]\n",
    "                    topk = list(set(topk + local_topk))\n",
    "                    print(f'Number of topk {len(topk)} in epoch {epoch}')\n",
    "\n",
    "                # Validation\n",
    "                if (epoch + 1) % args.test_every == 0:\n",
    "                    val_dset.setmode(1)\n",
    "                    val_probs, val_loss, val_acc, val_preds,val_conf = inference(epoch, val_loader, model, criterion)\n",
    "                    val_probs = np.transpose(val_probs.transpose() * val_conf)\n",
    "                    val_slide_mjvt, _ = aggregator.compute_aggregated_predictions(\n",
    "                        np.array(val_dset.slideIDX), val_preds\n",
    "                    )\n",
    "\n",
    "                    # We only keep avg, max, top10\n",
    "                    val_slide_avg = []\n",
    "                    val_slide_max = []\n",
    "                    val_slide_avgt10 = []\n",
    "\n",
    "                    # We'll store each class aggregator\n",
    "                    for cl in range(num_classes):\n",
    "                        t_avg, t_max = aggregator.compute_aggregated_probabilities(\n",
    "                            np.array(val_dset.slideIDX), val_probs[:, cl]\n",
    "                        )\n",
    "                        t_t10 = aggregator.group_avg_df(\n",
    "                            np.array(val_dset.slideIDX), val_probs[:, cl]\n",
    "                        )\n",
    "                        val_slide_avg.append(t_avg)\n",
    "                        val_slide_max.append(t_max)\n",
    "                        val_slide_avgt10.append(t_t10)\n",
    "\n",
    "                    val_slide_avg = np.array(val_slide_avg).transpose()\n",
    "                    val_slide_max = np.array(val_slide_max).transpose()\n",
    "                    val_slide_avgt10 = np.array(val_slide_avgt10).transpose()\n",
    "\n",
    "                    val_slide_avg_m = np.argmax(val_slide_avg, axis=1)\n",
    "                    val_slide_max_m = np.argmax(val_slide_max, axis=1)\n",
    "                    val_slide_avgt10_m = np.argmax(val_slide_avgt10, axis=1)\n",
    "\n",
    "                    from sklearn.metrics import f1_score\n",
    "                    f1_mv = f1_score(val_dset.targets, val_slide_mjvt, average='macro')\n",
    "                    f1_avg = f1_score(val_dset.targets, val_slide_avg_m, average='macro')\n",
    "                    f1_max = f1_score(val_dset.targets, val_slide_max_m, average='macro')\n",
    "                    f1_a10 = f1_score(val_dset.targets, val_slide_avgt10_m, average='macro')\n",
    "                    bacc_mv = balanced_accuracy_score(val_dset.targets, val_slide_mjvt)\n",
    "                    bacc_avg = balanced_accuracy_score(val_dset.targets, val_slide_avg_m)\n",
    "                    bacc_max = balanced_accuracy_score(val_dset.targets, val_slide_max_m)\n",
    "                    bacc_avgt10 = balanced_accuracy_score(val_dset.targets, val_slide_avgt10_m)\n",
    "                    \n",
    "                    auc_val_avg = evaluator.compute_auc(val_dset.targets, val_slide_avg)\n",
    "                    auc_val_max = evaluator.compute_auc(val_dset.targets, val_slide_max)\n",
    "                    auc_val_top10 = evaluator.compute_auc(val_dset.targets, val_slide_avgt10)\n",
    "\n",
    "                    fconv = open(os.path.join(args.output, 'valid_convergence.csv'), 'a')\n",
    "                    fconv.write('{},{:0.4f},{:3d},{:0.4f},{:0.4f},{:0.4f},{:0.4f},{:0.4f},{:0.4f},{:0.4f},{:0.4f},{:0.4f},{:0.4f},{:0.4f},{:0.4f}\\n'.format(\n",
    "                        epoch, val_loss, int(val_acc * 100),\n",
    "                        max(f1_mv,f1_avg, f1_max, f1_a10),\n",
    "                        f1_avg, f1_max, f1_a10,\n",
    "                        # save max and individual balanced accuracies\n",
    "                        max(bacc_mv, bacc_avg, bacc_max, bacc_avgt10),\n",
    "                        bacc_avg, bacc_max, bacc_avgt10,\n",
    "                        # also save best auc values\n",
    "                        max(auc_val_avg, auc_val_max, auc_val_top10),\n",
    "                        auc_val_avg, auc_val_max, auc_val_top10\n",
    "                    ))\n",
    "                    fconv.close()\n",
    "\n",
    "                    print(\"\\n----------------------Validation Results -------------------------------------\")\n",
    "                    print(f\"F1-scores (Val): MV={f1_mv:.3f}  AVG={f1_avg:.3f}  MAX={f1_max:.3f}  top10={f1_a10:.3f}\")\n",
    "                    print(f\"Balanced Acc (Val): MV={bacc_mv:.3f}  AVG={bacc_avg:.3f}  MAX={bacc_max:.3f}  top10={bacc_avgt10:.3f}\")\n",
    "                    print(f\"AUC-scores (Val): AVG={auc_val_avg:.3f}  MAX={auc_val_max:.3f}  top10={auc_val_top10:.3f}\")\n",
    "                    print(\"------------------------------------------------------------------\\n\")\n",
    "                    \n",
    "                    best_f1_candidate = max(f1_mv, f1_avg, f1_max, f1_a10)\n",
    "                    if best_f1_candidate > best_f1_v:\n",
    "                        best_f1_v = best_f1_candidate\n",
    "                        obj = {\n",
    "                            'epoch': epoch + 1,\n",
    "                            'state_dict': model.state_dict(),\n",
    "                            'best_ap_v': best_f1_v,\n",
    "                            'best_auc_v': max(auc_val_max, auc_val_top10, auc_val_avg),\n",
    "                            'optimizer': optimizer.state_dict()\n",
    "                        }\n",
    "                        torch.save(obj, os.path.join(args.output, 'checkpoint_best_F1.pth'))\n",
    "                        print(\"Saved checkpoint_best_F1.pth\")\n",
    "                        # save the tile level predictions for validation slides columns slideidx, prob non msi, prob msi and pred tile\n",
    "                        df2_f1 = pd.DataFrame({\n",
    "                            'slideidx': val_dset.slideIDX,\n",
    "                            'nonMSI_prob': val_probs[:, 0],\n",
    "                            'MSI_prob': val_probs[:, 1],\n",
    "                            'pred_tile': val_preds\n",
    "                        })\n",
    "                        df2_f1.to_csv(os.path.join(args.output, 'val_tile_pred_F1.csv'), index=False)\n",
    "\n",
    "                    best_auc_candidate = max(auc_val_avg, auc_val_max, auc_val_top10)\n",
    "                    if best_auc_candidate > best_auc_v:\n",
    "                        best_auc_v = best_auc_candidate\n",
    "                        obj = {\n",
    "                            'epoch': epoch + 1,\n",
    "                            'state_dict': model.state_dict(),\n",
    "                            'best_ap_v': best_f1_v,\n",
    "                            'best_auc_v': best_auc_v,\n",
    "                            'optimizer': optimizer.state_dict()\n",
    "                        }\n",
    "                        torch.save(obj, os.path.join(args.output, 'checkpoint_best_AUC.pth'))\n",
    "                        print(\"Saved checkpoint_best_AUC.pth\")\n",
    "\n",
    "                        # save the tile level predictions for validation slides columns slideidx, prob non msi, prob msi and pred tile\n",
    "                        df2_auc = pd.DataFrame({\n",
    "                            'slideidx': val_dset.slideIDX,\n",
    "                            'nonMSI_prob': val_probs[:, 0],\n",
    "                            'MSI_prob': val_probs[:, 1],\n",
    "                            'pred_tile': val_preds\n",
    "                        })\n",
    "                        df2_auc.to_csv(os.path.join(args.output, 'val_tile_pred_AUC.csv'), index=False)\n",
    "\n",
    "            # Save ground truth for validation slides\n",
    "            df1 = pd.DataFrame({\n",
    "                'Case_ID': val_dset.cases,\n",
    "                'WSI_Id': val_dset.slides,\n",
    "                'n_tiles': val_dset.ntiles,\n",
    "                'label_desc': val_dset.label_desc,\n",
    "                'label_id': val_dset.targets\n",
    "            })\n",
    "            df1.to_csv(os.path.join(args.output, 'val_GT.csv'), index=False)\n",
    "            df2_f1.to_csv(os.path.join(args.output, 'val_tile_pred_F1.csv'), index=False)\n",
    "            df2_auc.to_csv(os.path.join(args.output, 'val_tile_pred_AUC.csv'), index=False)\n",
    "            ############## Test ##############\n",
    "            ch = torch.load(os.path.join(args.output, 'checkpoint_best_AUC.pth'))\n",
    "            model.load_state_dict(ch['state_dict'])\n",
    "\n",
    "            test_dset.setmode(1)\n",
    "            test_probs, test_loss, test_acc, test_preds,test_conf = inference(epoch, test_loader, model, criterion)\n",
    "            test_probs = np.transpose(test_probs.transpose() * test_conf)\n",
    "            print(f'Predicted Tiles: {len(test_probs[:, 1])}, classes: {len(test_probs[0, :])}, total targets: {len(test_dset.targets)}')\n",
    "\n",
    "            test_slide_mjvt, _ = aggregator.compute_aggregated_predictions(\n",
    "                np.array(test_dset.slideIDX), test_preds\n",
    "            )\n",
    "            test_slide_avg = []\n",
    "            test_slide_max = []\n",
    "            test_slide_avgt10 = []\n",
    "            for cl in range(num_classes):\n",
    "                t_avg, t_max = aggregator.compute_aggregated_probabilities(\n",
    "                    np.array(test_dset.slideIDX), test_probs[:, cl]\n",
    "                )\n",
    "                t_t10 = aggregator.group_avg_df(\n",
    "                    np.array(test_dset.slideIDX), test_probs[:, cl]\n",
    "                )\n",
    "                test_slide_avg.append(t_avg)\n",
    "                test_slide_max.append(t_max)\n",
    "                test_slide_avgt10.append(t_t10)\n",
    "\n",
    "            test_slide_avg = np.array(test_slide_avg).transpose()\n",
    "            test_slide_max = np.array(test_slide_max).transpose()\n",
    "            test_slide_avgt10 = np.array(test_slide_avgt10).transpose()\n",
    "\n",
    "            test_slide_avg_m = np.argmax(test_slide_avg, axis=1)\n",
    "            test_slide_max_m = np.argmax(test_slide_max, axis=1)\n",
    "            test_slide_avgt10_m = np.argmax(test_slide_avgt10, axis=1)\n",
    "\n",
    "            f1_mv = f1_score(test_dset.targets, test_slide_mjvt, average='macro')\n",
    "            f1_avg = f1_score(test_dset.targets, test_slide_avg_m, average='macro')\n",
    "            f1_max = f1_score(test_dset.targets, test_slide_max_m, average='macro')\n",
    "            f1_t10 = f1_score(test_dset.targets, test_slide_avgt10_m, average='macro')\n",
    "            # balanced accuracy\n",
    "            bacc_mv = balanced_accuracy_score(test_dset.targets, test_slide_mjvt)\n",
    "            bacc_avg = balanced_accuracy_score(test_dset.targets, test_slide_avg_m)\n",
    "            bacc_max = balanced_accuracy_score(test_dset.targets, test_slide_max_m)\n",
    "            bacc_avgt10 = balanced_accuracy_score(test_dset.targets, test_slide_avgt10_m)\n",
    "            # AUC\n",
    "            auc_test_avg = evaluator.compute_auc(test_dset.targets, test_slide_avg)\n",
    "            auc_test_max = evaluator.compute_auc(test_dset.targets, test_slide_max)\n",
    "            auc_test_top10 = evaluator.compute_auc(test_dset.targets, test_slide_avgt10)\n",
    "            print(\"\\n----------------------Test Set Results-------------------------------\")\n",
    "            print(f\"Test F1-scores: MV={f1_mv:.3f}, AVG={f1_avg:.3f}, MAX={f1_max:.3f}, top10={f1_t10:.3f}\")\n",
    "            print(f\"Test Balanced Acc: MV={bacc_mv:.3f}, AVG={bacc_avg:.3f}, MAX={bacc_max:.3f}, top10={bacc_avgt10:.3f}\")\n",
    "            print(f\"Test AUC-scores: AVG={auc_test_avg:.3f}, MAX={auc_test_max:.3f}, top10={auc_test_top10:.3f}\")\n",
    "            # confusion matrix of average predictions only\n",
    "            print(\"Confusion Matrix (Average Predictions):\")\n",
    "            print(confusion_matrix(test_dset.targets, test_slide_avg_m))\n",
    "            # classification report of average predictions only\n",
    "            print(\"Classification Report (Average Predictions):\")\n",
    "            print(classification_report(test_dset.targets, test_slide_avg_m))\n",
    "            print(\"------------------------------------------------------\\n\")\n",
    "            # save the ground truth for test slides\n",
    "            df1 = pd.DataFrame({\n",
    "                'Case_ID': test_dset.cases,\n",
    "                'WSI_Id': test_dset.slides,\n",
    "                'n_tiles': test_dset.ntiles,\n",
    "                'label_desc': test_dset.label_desc,\n",
    "                'label_id': test_dset.targets\n",
    "            })\n",
    "            df1.to_csv(os.path.join(args.output, 'test_GT.csv'), index=False)\n",
    "            # save the average predictions of the test slides\n",
    "            df2 = pd.DataFrame({\n",
    "                'wsi_id': test_dset.slides,\n",
    "                'nonMSI_prob': test_slide_avg[:, 0],\n",
    "                'MSI_prob': test_slide_avg[:, 1]\n",
    "            })\n",
    "            df2.to_csv(os.path.join(args.output, 'test_pred_avg_AUC.csv'), index=False)\n",
    "            # save the max predictions of the test slides\n",
    "            df3 = pd.DataFrame({\n",
    "                'wsi_id': test_dset.slides,\n",
    "                'nonMSI_prob': test_slide_max[:, 0],\n",
    "                'MSI_prob': test_slide_max[:, 1]\n",
    "            })\n",
    "            df3.to_csv(os.path.join(args.output, 'test_pred_max_AUC.csv'), index=False)\n",
    "            # save the top10 predictions of the test slides\n",
    "            df4 = pd.DataFrame({\n",
    "                'wsi_id': test_dset.slides,\n",
    "                'nonMSI_prob': test_slide_avgt10[:, 0],\n",
    "                'MSI_prob': test_slide_avgt10[:, 1]\n",
    "            })\n",
    "            df4.to_csv(os.path.join(args.output, 'test_pred_t10_AUC.csv'), index=False)\n",
    "            # save original tile level predictions for test slides\n",
    "            df5 = pd.DataFrame({\n",
    "                'slideidx': test_dset.slideIDX,\n",
    "                'nonMSI_prob': test_probs[:, 0],\n",
    "                'MSI_prob': test_probs[:, 1],\n",
    "                'pred_tile': test_preds\n",
    "            })\n",
    "            df5.to_csv(os.path.join(args.output, 'test_tile_pred_AUC.csv'), index=False)\n",
    "            \n",
    "            print('..............Test set done ...............')\n",
    "\n",
    "            print(\"Done setting up 5-crop pipeline for fold \", fold + 1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6924515,
     "sourceId": 45867,
     "sourceType": "competition"
    },
    {
     "datasetId": 4326425,
     "sourceId": 7434237,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4326441,
     "sourceId": 7434258,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4683086,
     "sourceId": 7960962,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 190609205,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 191828727,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "tcga",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14179.520569,
   "end_time": "2024-02-04T02:21:21.419555",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-03T22:25:01.898986",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
